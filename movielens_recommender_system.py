# -*- coding: utf-8 -*-
"""Movielens Recommender System Final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rW5V21Otw3XVTC7UdwGzxalnECKi2tiO

# **Import library yang dibutuhkan**
"""

import numpy as np
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import tensorflow as tf
from tensorflow import keras
from sklearn.model_selection import train_test_split

import matplotlib.pyplot as plt
import seaborn as sns
import re
from collections import Counter

from datetime import datetime
import warnings

warnings.filterwarnings("ignore")

# readme file
txt_files = '/content/README.txt'
with open(txt_files, 'r') as file:
    content = file.read()
    print(content)

"""Berdasarkan informasi yang diperoleh dari readme file, saya akan menggunakan dataset movies.csv dan ratings.csv untuk keperluan pembuatan sistem rekomendasi.

# **Data Understanding**

Dataset yang digunakan berasal dari [Movielens Latest Datasets](https://grouplens.org/datasets/movielens/latest/). Dataset yang saya ambil adalah kategori small yang berisikan 100.000 rating dan 3.600 aplikasi tag yang diterapkan pada 9.000 film oleh 600 pengguna. Adapun terakhir kali diperbarui pada 9/2018. Dataset ini sering digunakan untuk pengembangan dan evaluasi sitem rekomendasi.

## Data Loading

Pada saat load dataset saya hanya memilih dataset movies dan ratings untuk keperluan pembuatan sistem rekomendasi
"""

# Load dataset yang digunakan

movies = pd.read_csv('/content/movies.csv')
ratings = pd.read_csv('/content/ratings.csv')

print(f'Jumlah data film dalam dataset movies: {movies.movieId.nunique()}')
print(f'Jumlah data ratings atau penilaian dalam dataset ratings: {ratings.movieId.nunique()}')

# cek tipe data dataset movies
movies.info()

"""Dataset movies memiliki struktur sebagai berikut:
1. `movieId`: Id unik untuk setiap film
2. `tittle`: judul film disertai tahun rilis fim
3. `genres`: genre film yang dipisahkan dengan karkater '|', contohnya Comedy|Romance

Struktur dataset movies memiliki informasi lengkap tentang jumlah kolom dan baris, tipe data, serta jumlah nilai non-null di setiap kolom.
"""

# cek tipe data dataset ratings
ratings.info()

"""Dataset ratings memiliki struktur sebagai berikut:
1. `userId`: ID unik untuk setiap pengguna
2. `movieID`: ID film yang diberi rating oleh pengguna
3. `rating`: peringkat atau nilai rating yang diberikan oleh pengguna (skala 0.5 - 5.0 dengan interval 0.5)
4. `timestamp`: waktu ketika penilaian (rating) diberikan

Struktur dataset ratings memiliki informasi yang lengkap tentang jumlah kolom dan baris, tipe data, serta jumlah nilai non-null di setiap kolom.

## Data preparation
"""

# cek dataset film
movies

# Menyimpan tahun rilis di kolom baru 'year_of_release'
movies['year_of_release'] = movies['title'].str.extract(r'\((\d{4})\)', expand=False)

# Menghapus tahun dari judul film
movies['title'] = movies['title'].str.replace(r'\(\d{4}\)', '', regex=True)

# Menghapus spasi tambahan setelah penghapusan tahun
movies['title'] = movies['title'].str.strip()

# Menampilkan hasil
movies.head()

# Mengubah year_of_release menjadi numerik
movies['year_of_release'] = pd.to_numeric(movies['year_of_release'], errors='coerce')

# Menampilkan tipe data baru
print(movies.dtypes)

# cek dataset rating
ratings

# cek nilai unik dalam kolom rating
ratings['rating'].unique()

from collections import Counter

# Mengelompokkan rating berdasarkan movieId dan menghitung rata-rata serta jumlah rating
movie_ratings = ratings.groupby('movieId')['rating'].agg(['mean', 'count']).reset_index()

# Menghitung jumlah genre untuk setiap film di dataset movies
movies['genre_count'] = movies['genres'].apply(lambda x: len(x.split('|')))

# Membuat daftar dari semua genre yang ada dalam dataset movies untuk analisis distribusi genre
all_genres = []
for genres in movies['genres']:
    # Memisahkan string genre dan menambahkannya ke daftar all_genres
    all_genres.extend(genres.split('|'))

# Menghitung frekuensi kemunculan setiap genre
genres_count = Counter(all_genres)

print(f"Ditemukan {len(genres_count)} genre unik")

# Menampilkan genre dan jumlahnya
print("Genre dan jumlah kemunculannya:")
for genre, count in genres_count.items():
    print(f"{genre}: {count}")

"""Ditemukan kategori no genre listed sebanyak 34 film, nantinya kategori ini akan dihapus karena jumlahnya yang sedikit daripada total film 9000an. Hal ini dikarenakan no genre listed dianggap missing values sehingga dapat memengaruhi sistem rekomendasi."""

# mengonversi timestamp menjadi date time
ratings['timestamp'] = pd.to_datetime(ratings['timestamp'], unit='s')

ratings.head(10)

"""Untuk sementara, dataframe user ratings sudah terlihat cukup baik."""

# menggabungkan dataframe movies dan ratings menjadi satu dataframe films utuh
films = pd.merge(ratings, movies, on='movieId', how='left')
films

"""Dataset digabung menggunakan metode `left join` dengan kolom `movieId` sebagai kunci penghubung. Pendekatan ini memastikan bahwa seluruh informasi rating tetap terjaga, sementara detail mengenai film ditambahkan ke setiap data rating yang relevan. Hasil dari penggabungan ini memungkinkan analisis preferensi pengguna terhadap film berdasarkan karakteristiknya dalam tahap Exploratory Data Analysis (EDA).

"""

# mengecek missing values dalam dataset

print(f'Jumlah missing values dalam dataset films: {films.isnull().sum()}')

# menghapus missing values dalam dataset

films = films.dropna()
films

# cek kembali missing values dalam dataset

print(f'Jumlah missing values dalam dataset films: {films.isnull().sum()}')

"""Saat pengecekan jumlah genres unik dalam dataset, ditemukan kategori no genre listed pada kolom genre. Ini akan memengaruhi sistem rekomendasi pada contend-based diltering. Oleh karena itu mengingat jumlah datanya sedikit maka saya memilih menghapusnya."""

# menghapus kategori no genres listed pada kolom genres untuk dataset gabungan films
films = films[films['genres'] != '(no genres listed)']
films

# mengecek duplikasi data dalam dataset films

print(f'Jumlah duplikasi data dalam dataset films: {films.duplicated().sum()}')

# menghapus kategori no genres listed pada kolom genres untuk dataset movies
movies = movies[movies['genres'] != '(no genres listed)']
movies

# mengecek duplikasi data dalam dataset movies

print(f'Jumlah duplikasi data dalam dataset movies: {movies.duplicated().sum()}')

"""Saat menampilkan daftar genre film, saya memperhatikan adanya kategori **'Sci-Fi'**. **'Sci-Fi'** merupakan akronim dari **'Science Fiction'**, yang merujuk pada film bertema fiksi ilmiah. Namun, penggunaan tanda hubung (`-`) dalam akronim ini berpotensi menimbulkan masalah dalam tahap **vektorisasi TF-IDF**, karena sistem akan memisahkannya menjadi dua kata terpisah: **'Sci'** dan **'Fi'**, yang dapat mengganggu pemrosesan teks dan pemetaan genre secara akurat. Oleh karena itu, pemisah ini sebaiknya dihilangkan agar istilah tetap dikenali sebagai satu kesatuan dan tetap merepresentasikan genre fiksi ilmiah dengan benar dalam analisis data.

"""

# mengubah Sci-Fi menjadi Scifi
films = films.replace(to_replace ='[nS]ci-Fi', value = 'Scifi', regex = True)
films.head()

# mengubah Sci-Fi menjadi Scifi pada dataset movies
movies = movies.replace(to_replace ='[nS]ci-Fi', value = 'Scifi', regex = True)
movies.head()

"""## Ekstraksi Fitur dengan TF-IDF"""

# TF-IDF pada data genre film
tfidf = TfidfVectorizer(token_pattern=r'[^|]+') # karena genre dipisahkan dengan karakter "|"
tfidf_matrix = tfidf.fit_transform(movies['genres'])

# Melihat dimensi matriks TF-IDF
print(f"Dimensi matriks TF-IDF: {tfidf_matrix.shape}")

"""Pada tahapan di atas, saya telah melakukan ekstraksi fitur utama yang diperlukan untuk membangun model rekomendasi berbasis konten:  

- **TF-IDF Vectorization**: Teknik ini digunakan untuk mengubah informasi genre ke dalam format numerik. TF-IDF membantu menentukan tingkat kepentingan setiap genre dalam suatu film dengan mempertimbangkan distribusinya di seluruh dataset.  

- **Konfigurasi Token Pattern**: Karena genre dalam dataset dipisahkan oleh karakter '|', pola token khusus (`token_pattern=r'[^|]+'`) diterapkan agar setiap genre dikenali sebagai satu token terpisah oleh TF-IDF.  

- **Matriks TF-IDF** yang telah terbentuk nantinya akan digunakan dalam pengembangan model **Content-Based Filtering**, memungkinkan sistem rekomendasi memberikan saran film yang lebih sesuai dengan preferensi pengguna.

# **Exploratory Data Analysis**
"""

# Statistik deskriptif untuk dataset movies
print("Statistik Deskriptif untuk Dataset Movies:")
movies.describe()

"""Berdasarkan hasil statistik deskriptif yang ditampilkan, terdapat beberapa informasi yang diperoleh mengenai kolom-kolom numerik dalam dataset movies yakni
- `movieId`: nilai ID berkisar antara 1 hingga 193609 dengan rata-rata 41798. Sebagian besar ID film berada dalam kisaran 3233 hingga 74809 (kuartil ke-1 hingga ke-3)
- `year_of_release`: tahun rilis berkisar antara tahun 1902 hingga 2018 dengan rata-rata di tahun 1994. Sebagian besar film berada dalam kisaran tahun 1987 hingga 2008 (kuartil ke-1 hingga ke-3)
- `genre_count`: jumlah genre yang dimiliki oleh tiap film berkisar antara 1 hingga 10 dengan rata-rata 2 genre. Sebagian besar film memiliki genre dalam kisaran 1 hingga 3 (kuartil ke-1 hingga ke-3)
"""

# Statistik deskriptif untuk dataset rating
print("Statistik Deskriptif untuk Dataset Ratings:")
ratings.describe()

"""Berdasarkan hasil statistik deskriptif yang ditampilkan, terdapat beberapa informasi yang diperoleh mengenai kolom-kolom numerik dalam dataset ratings, yakni:
1. `userId`: ID pengguna berkisar antara 1 hingga 610 dengan rata-rata ID pengguna berada di angka 326. Sebagian besar memiliki ID dalam kisaran 177 hingga 477 (kuartil ke-1 hingga ke-3)
2. `movieId`: ID film yang diberi rating oleh pengguna berada dalam rentang 1 hingga 193609 dengan rata-rata 19435. Sebagian besar film yang diberi rating berada dalam ID 1199 hingga 8122. Ini menunjukkan bahwa film-film dengan ID lebih kecil cenderung lebih banyak diberi rating.
3. `rating`: rating yang diberikan pengguna berkisar antara 0,5 hingga 5 dengan rata-rata rating adalah 3,5. Sebagian besar rating berada pada rentang 3,0 hingga 4,0. Ini menunjukkan adanya kecenderungan pengguna memberikan rating cukup positif terhadap film yang mereka tonton.
4. `timestamp`: aktivitas rating yang dilakukan oleh pengguna berkisar antara pukul 18.36 tanggal 29/3/1996 hingga pukul 14.27 tanggal 24/9/2018 dengan rata-rata aktivitas rating yang dilakukan pengguna berkisar pada pukul 17.01 tanggal 19/3/2008. Kemudian sebagian besar aktivitas rating dilakukan antara pukul 09.57 tanggal 18/4/2002 hingga pukul 07.15 tanggal 4/7/2015. Ini menunjukkan bahwa aktivitas dominan terjadi dalam kurun waktu tahun 2002 hingga 2015.
"""

# Statistik deksriptif untuk dataset gabungan
print("Statistik Deskriptif untuk Dataset Gabungan:")
films.describe()

"""Berdasarkan hasil statistik deskriptif dataset gabungan yang ditampilkan, terdapat beberap informasi yang diperoleh mengenai kolom-kolom numerik yakni:
1. `movieId`: ID film yang diberi rating oleh pengguna berkisar antara 1 hingga 193609 dengan rata-rata 19365. Sebagian besar film yang diberi rating berada dalam rentang ID 1198 hingga 8014. Ini menandakan bahwa ID lebih kecil cenderung memiliki lebih banyak film yang diberi rating.
2. `year_of_release`: tahun rilis film berkisar antara tahun 1902 hingga 2018 dengan rata-rata di tahun 1994. Sebagian besar film dirilis berada dalam kisaran tahun 1990 hingga 2003. Ini menandakan bahwa banyak film yang diproduksi pada rentang tahun 1990 hingga 2003.
3. `genre_count`: jumlah genre yang dimiliki oleh tiap film berkisar antara 1 hingga 10 dengan rata-rata 2 genre. Sebagian besar film memiliki genre dalam kisaran 1 hingga 3 (kuartil ke-1 hingga ke-3). Ini menandakan bahwa banyak film yang memiliki banyak genre.
4. `userId`: ID pengguna berkisar antara 1 hingga 510 edngan rata-rata ID pengguna berada di angka 326. Sebagian besar pengguna memiliki ID dalam kisaran 177 hinga 477. Ini menunjukkan bahwa kecenderungan pengguna yang memberi rating adalah pada rentang ID pengguna 177 hingga 477.
5. `rating`: rating yang diberikan pengguna berkisar antara 0,5 hingga 5 dengan rata-rata rating adalah 3,5. Sebagian besar rating berada pada rentang 3,0 hingga 4,0. Ini menunjukkan adanya kecenderungan pengguna memberikan rating cukup positif terhadap film yang mereka tonton.
6. `timestamp`: aktivitas rating yang dilakukan oleh pengguna berkisar antara pukul 18.36 tanggal 29/3/1996 hingga pukul 14.27 tanggal 24/9/2018 dengan rata-rata aktivitas rating yang dilakukan pengguna berkisar pada pukul 18.34 tanggal 17/3/2008. Kemudian sebagian besar aktivitas rating dilakukan antara pukul 12.46 tanggal 7/4/2002 hingga pukul 07.04 tanggal 4/7/2015. Ini menunjukkan bahwa aktivitas dominan terjadi dalam kurun waktu tahun 2002 hingga 2015.
"""

# Menghitung rata-rata rating per film
movie_ratings = ratings.groupby('movieId')['rating'].mean().reset_index()

# Plot distribusi rating
plt.figure(figsize=(10, 6))
sns.histplot(movie_ratings['rating'], bins=20, kde=True, color='blue')

# Menambahkan label dan judul
plt.xlabel("Rata-rata Rating Film")
plt.ylabel("Frekuensi")
plt.title("Distribusi Rata-rata Rating Film")
plt.grid(True)

plt.show()

"""Grafik distribusi rata-rata rating film menunjukkan bahwa mayoritas pengguna cenderung memberikan rating 3.5 dengan frekuensi sekitar 1400 lebih pengguna. Informasi lainnya, sebagian besar rating berkisar antara 3.0 dan 4.0 menunjukkan kecenderungan pengguna untuk menilai film secara positif.  """

# Langkah 1: Menampilkan Distribusi Genre Film
plt.figure(figsize=(12, 8))

# Mengurutkan genre berdasarkan jumlah kemunculan dan mengubahnya ke dalam format dataframe
sorted_genres = sorted(genres_count.items(), key=lambda x: x[1], reverse=True)
genre_df = pd.DataFrame(sorted_genres, columns=['genre', 'count'])

# Memvisualisasikan 15 genre paling populer dalam dataset
sns.barplot(x='count', y='genre', data=genre_df.head(10), palette='viridis')
plt.title('10 Genre Film Paling Populer', fontsize=16)
plt.xlabel('Jumlah Film', fontsize=12)
plt.ylabel('Genre', fontsize=12)
plt.tight_layout()
plt.show()

# Langkah 2: Analisis Jumlah Genre dalam Film
plt.figure(figsize=(10, 6))

# Menghitung variasi jumlah genre per film berdasarkan dataset movies
movies_genre_distribution = movies[['movieId', 'genre_count']].copy()

# Memvisualisasikan sebaran jumlah genre dalam setiap film
sns.countplot(x='genre_count', data=movies_genre_distribution, palette='viridis')
plt.title('Distribusi Jumlah Genre per Film', fontsize=16)
plt.xlabel('Jumlah Genre', fontsize=12)
plt.ylabel('Jumlah Film', fontsize=12)
plt.show()

"""Berdasarkan visualisasi data distribusi genre film di atas memberikan infromasi bahwa genre film yang paling banyak diproduksi adalah Drama dan Comedy sebanyak masing-masing 4000an dan lebih dari 3500 film. Ini berarti kedua genre tersebut telah mendominasi dunia perfilman. Dilanjutkan genre Thriller, Action, dan Romance yang cukup populer menjadi top 3,4, dan 5 film teratas. Di sisi lain, sebagian besar film memiliki 1 hingga 3 genre dengan jumlah tertinggi terdapat pada film yang memiliki 2 genre, diikuti oleh 1 dan 3."""

# Plot distribusi tahun rilis film
plt.figure(figsize=(12, 6))
sns.histplot(films['year_of_release'], bins=30, kde=True, color='blue')

# Menambahkan label dan judul
plt.xlabel("Tahun Rilis")
plt.ylabel("Jumlah Film")
plt.title("Distribusi Tahun Rilis Film (Dataset Gabungan)")
plt.grid(axis='y', linestyle='--', alpha=0.7)

plt.show()

"""Distribusi jumlah film yang dirilis setiap tahun menunjukkan pola pertumbuhan yang mencerminkan dinamika industri perfilman selama lebih dari satu abad. Pada periode sebelum tahun 1970, produksi film berlangsung dalam skala yang lebih terbatas, dengan jumlah rilis yang cenderung stabil di bawah 50 film per tahun. Namun, memasuki dekade 1970-an, terjadi percepatan signifikan dalam jumlah produksi, yang kemudian meningkat lebih tajam setelah tahun 1980. Tren ini mencapai puncaknya pada awal 2000-an, dengan jumlah film yang dirilis per tahun melampaui 300 judul, menandai era ekspansi industri secara masif. Setelah tahun 2015, terlihat adanya penurunan tajam dalam jumlah film yang tercatat, yang kemungkinan besar bukan akibat dari berkurangnya produksi, melainkan keterbatasan data terbaru yang belum sepenuhnya terakumulasi. Secara keseluruhan, grafik ini mengilustrasikan bagaimana industri film mengalami evolusi yang pesat, didorong oleh berbagai faktor seperti teknologi, permintaan pasar, dan perubahan lanskap distribusi film dalam beberapa dekade terakhir.

"""

movie_ratings = ratings.groupby('movieId')['rating'].agg(['mean', 'count']).reset_index()

plt.figure(figsize=(12, 6))
sns.histplot(movie_ratings['count'], bins=30, kde=True, color='green')

plt.xlabel("Jumlah Rating Per Film")
plt.ylabel("Frekuensi Film")
plt.title("Distribusi Jumlah Rating Per Film")
plt.grid(axis='y', linestyle='--', alpha=0.7)

plt.show()

"""Histogram distribusi jumlah rating per film menunjukkan bahwa mayoritas film dalam dataset hanya menerima sedikit rating dari pengguna, dengan sebagian besar berada di kisaran 0–10 rating. Pola ini mencerminkan adanya long-tail effect, di mana hanya sejumlah kecil film yang menarik perhatian luas dan mendapatkan banyak ulasan, sementara sebagian besar film kurang dikenal atau kurang diminati. Tren ini mengindikasikan bahwa persebaran rating tidak merata, dengan beberapa film yang berhasil membangun popularitas besar, kemungkinan karena faktor seperti pemasaran, kualitas produksi, atau keterlibatan komunitas.

# **Modelling**

## Content-Based Filtering
"""

# Mengubah bentuk tf-idf vektor menjadi matriks
tfidf_matrix.todense()

# Konversi ke DataFrame dengan nama kolom sesuai fitur TF-IDF
df_tfidf = pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tfidf.get_feature_names_out(),
    index=movies['title']
)

# Pastikan jumlah sampel tidak melebihi ukuran dataset
num_columns = min(20, df_tfidf.shape[1])  # Menyesuaikan jumlah kolom
num_rows = min(10, df_tfidf.shape[0])  # Menyesuaikan jumlah baris

# Sampling untuk menampilkan sebagian data
df_sampled = df_tfidf.sample(num_columns, axis=1).sample(num_rows, axis=0)

# Menampilkan hasil
df_sampled

# Hitung cosine similarity pada matrix
cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

# Buat dataframe hasil dari cosine similarity
cosine_sim_df = pd.DataFrame(cosine_sim, index=movies['title'], columns=movies['title'])
print('Shape:', cosine_sim_df.shape)

# Tampilkan similarity matrix
cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

# Fungsi rekomendasi
def film_recommendations(title, similarity_data=cosine_sim_df, items=movies[['title', 'genres']], k=5):
    index = similarity_data.loc[:,title].to_numpy().argpartition(
        range(-1, -k, -1))
    closest = similarity_data.columns[index[-1:-(k+2):-1]]

    # Ketik film yang ingin dicari
    closest = closest.drop(title, errors='ignore')

    return pd.DataFrame(closest).merge(items).head(k)

# Tampilkan 5 data awal
movies.head()

# Cek movies
movies[movies.title.eq('Steal Big, Steal Little')]

# Mencari film rekomendasi mirip Steal Big, Steal Little
film_recommendations('Steal Big, Steal Little')

"""## Collaborative Filtering"""

# Membaca dataset
df = films
df

"""### Data Preparation"""

# Mendapatkan daftar unik userId dalam bentuk list
unique_user_ids = df['userId'].drop_duplicates().tolist()
print("Daftar userID unik:", unique_user_ids)

# Melakukan encoding userId menjadi indeks numerik
user_id_to_index = {user: idx for idx, user in enumerate(unique_user_ids)}
print("Mapping userID ke indeks:", user_id_to_index)

# Membalik encoding: dari indeks numerik ke userId asli
index_to_user_id = {idx: user for idx, user in enumerate(unique_user_ids)}
print("Mapping indeks ke userID:", index_to_user_id)

# Mengambil daftar unik dari 'movieId' sebagai list
unique_movie_ids = df['movieId'].drop_duplicates().tolist()

# Melakukan encoding 'movieId' ke indeks numerik untuk pemrosesan lebih mudah
movie_to_index = {movie_id: index for index, movie_id in enumerate(unique_movie_ids)}

# Melakukan decoding indeks numerik kembali ke 'movieId' asli
index_to_movie = {index: movie_id for index, movie_id in enumerate(unique_movie_ids)}

# Menyesuaikan 'userId' dengan nilai yang telah dienkripsi dalam dataframe
df['user'] = df['userId'].map(user_id_to_index)

# Menyesuaikan 'movieId' dengan nilai yang telah dienkripsi dalam dataframe
df['films'] = df['movieId'].map(movie_to_index)

# Menentukan jumlah unik pengguna dalam dataset
num_users = len(user_id_to_index)
print(f"Jumlah Pengguna: {num_users}")

# Menentukan jumlah unik film dalam dataset
num_films = len(movie_to_index)
print(f"Jumlah Film: {num_films}")

# Mengonversi kolom rating ke tipe data float
df['rating'] = df['rating'].astype(np.float32)

# Menentukan nilai minimum dari rating dalam dataset
min_rating = df['rating'].min()

# Menentukan nilai maksimum dari rating dalam dataset
max_rating = df['rating'].max()
df['rating'] = df['rating'].apply(lambda r: (r - min_rating) / (max_rating - min_rating))

# Menampilkan hasil dalam format yang lebih terstruktur
print(f"Jumlah Pengguna: {num_users}, Jumlah Film: {num_films}, Rating Minimum: {min_rating}, Rating Maksimum: {max_rating}")

"""### Split Data Training & Validation"""

# Sampling
df = df.sample(frac=1, random_state=42)
df

# Menyatukan informasi pengguna dan film sebagai pasangan nilai
input_data = df[['user', 'films']].values

# Normalisasi rating agar berada dalam rentang 0-1
normalized_ratings = df['rating'].values

# Membagi dataset menjadi data latih (80%) dan validasi (20%)
split_index = int(0.8 * df.shape[0])
x_train, x_val = input_data[:split_index], input_data[split_index:]
y_train, y_val = normalized_ratings[:split_index], normalized_ratings[split_index:]

# Menampilkan hasil pemrosesan
print(input_data, normalized_ratings)

"""### Proses Training"""

# Class recommendations
class RecommenderNet(tf.keras.Model):
    def __init__(self, num_users, num_films, embedding_size=50, **kwargs):
        super(RecommenderNet, self).__init__(**kwargs)

        self.num_users = num_users
        self.num_films = num_films
        self.embedding_size = embedding_size

        # Embedding layer dengan regularisasi L2 untuk pengguna dan film
        self.user_embedding = tf.keras.layers.Embedding(
            input_dim=num_users,
            output_dim=embedding_size,
            embeddings_initializer='he_normal',
            embeddings_regularizer=keras.regularizers.l2(1e-5)
        )
        self.user_bias = tf.keras.layers.Embedding(num_users, 1)

        self.film_embedding = tf.keras.layers.Embedding(
            input_dim=num_films,
            output_dim=embedding_size,
            embeddings_initializer='he_normal',
            embeddings_regularizer=keras.regularizers.l2(1e-5)
        )
        self.film_bias = tf.keras.layers.Embedding(num_films, 1)

        # Menambahkan Dropout setelah embedding
        self.dropout = tf.keras.layers.Dropout(0.3)

    def call(self, inputs):
        # Mengambil embedding pengguna dan film
        user_vector = self.user_embedding(inputs[:, 0])
        user_bias = self.user_bias(inputs[:, 0])
        film_vector = self.film_embedding(inputs[:, 1])
        film_bias = self.film_bias(inputs[:, 1])

        # Operasi dot product antara pengguna dan film
        dot_product = tf.tensordot(user_vector, film_vector, axes=2)

        # Menjumlahkan hasil dot product dengan bias
        x = dot_product + user_bias + film_bias

        # Mengaplikasikan Dropout sebelum aktivasi
        x = self.dropout(x)

        # Aktivasi dengan fungsi sigmoid
        return tf.nn.sigmoid(x)

# Inisialisasi model
model = RecommenderNet(num_users, num_films, embedding_size=50)

# Compile model dengan BinaryCrossentropy, Adam optimizer, dan RMSE sebagai metrik evaluasi
model.compile(
    loss=tf.keras.losses.BinaryCrossentropy(),
    optimizer=keras.optimizers.Adam(learning_rate=0.0001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

# Callback early stopping untuk menghentikan training jika validation RMSE stagnan
early_stopping = tf.keras.callbacks.EarlyStopping(
    monitor='val_root_mean_squared_error',
    patience=5,
    verbose=1,
    mode='min',
    restore_best_weights=True
)

# Training model
history = model.fit(
    x_train, y_train,
    batch_size=16,
    epochs=25,
    validation_data=(x_val, y_val),
    callbacks=[early_stopping]
)

"""### Evaluasi Model"""

# Memvisualisasikan evaluasi metrik model
plt.figure(figsize=(8, 5))
plt.plot(history.history['root_mean_squared_error'], label="Train", color='blue')
plt.plot(history.history['val_root_mean_squared_error'], label="Validation", color='red')

# Menambahkan elemen grafik untuk memperjelas visualisasi
plt.title("Evaluasi Performa Model")
plt.xlabel("Epoch")
plt.ylabel("Root Mean Squared Error")
plt.legend(loc='upper left')
plt.grid(True)
plt.show()

"""### Mendapatkan Rekomendasi"""

# Films
films_df = movies.copy()
films_df.head()

# Data ratings
df = films.copy()
df.head()

# Mengambil sampel user
user_id = df.userId.sample(1).iloc[0]
films_visited_by_user = df[df.userId == user_id]

# bitwise operators (~), bisa diketahui di sini https://docs.python.org/3/reference/expressions.html
films_not_visited = films_df[~films_df['movieId'].isin(films_visited_by_user.movieId.values)]['movieId']
films_not_visited = list(
    set(films_not_visited)
    .intersection(set(index_to_user_id.keys()))
)

films_not_visited = [[index_to_user_id.get(x)] for x in films_not_visited]
user_encoder = user_id_to_index.get(user_id)
user_films_array = np.hstack(
    ([[user_encoder]] * len(films_not_visited), films_not_visited)
)

# Mendapatkan rekomendasi
ratings = model.predict(user_films_array).flatten()

top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_films_ids = [
    index_to_movie.get(films_not_visited[x][0]) for x in top_ratings_indices
]

print('Showing recommendations for users: {}'.format(user_id))
print('===' * 9)
print('Films with high ratings from user')
print('----' * 8)

top_films_user = (
    films_visited_by_user.sort_values(
        by = 'rating',
        ascending=False
    )
    .head(5)
    .movieId.values
)

films_df_rows = films_df[films_df['movieId'].isin(top_films_user)]
for row in films_df_rows.itertuples():
    print(row.title, ':', row.genres)

print('----' * 8)
print('Top 10 films recommendation')
print('----' * 8)

recommended_films = films_df[films_df['movieId'].isin(recommended_films_ids)]
for row in recommended_films.itertuples():
    print(row.title, ':', row.genres)